import Foundation
import KanaKanjiConverterModule

// MARK: - N-gram Training
extension TextModel {
    /// æ–°è¦ã‚¨ãƒ³ãƒˆãƒªã‚’ä½¿ç”¨ã—ã¦N-gramãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ å­¦ç¿’
    /// - Parameters:
    ///   - newEntries: æ–°è¦ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªã®é…åˆ—
    ///   - ngramSize: N-gramã®ã‚µã‚¤ã‚º
    ///   - baseFilename: ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å
    func trainNGramOnNewEntries(newEntries: [TextEntry], ngramSize: Int, baseFilePattern: String) async {
        let lines = newEntries.map { $0.text }
        if lines.isEmpty {
            return
        }
        let fileManager = self.fileManager
        let outputDirURL = getLMDirectory() // Use the LM directory function
        let outputDir = outputDirURL.path
        
        do {
            try fileManager.createDirectory(atPath: outputDir, withIntermediateDirectories: true, attributes: nil)
        } catch {
            print("âŒ Failed to create directory: \(error)")
            return
        }
        
        // WIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆã‚³ãƒ”ãƒ¼å‡¦ç†ã¯å‰Šé™¤ï¼‰
        let wipFileURL = URL(fileURLWithPath: outputDir).appendingPathComponent("\(baseFilePattern).wip")
        do {
            try "Training in progress".write(to: wipFileURL, atomically: true, encoding: .utf8)
        } catch {
            print("âŒ Failed to create WIP file: \(error)")
        }
        
        // KanaKanjiConverterModule ã® N-gram å­¦ç¿’æ©Ÿèƒ½ã‚’ä½¿ç”¨
        do {
            print("ğŸ”„ Starting N-gram training with \\(lines.count) entries...")
            
            // KanaKanjiConverterModuleã®N-gramå­¦ç¿’æ©Ÿèƒ½ã‚’ä½¿ç”¨
            // å®Ÿè£…ãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€åˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            print("âš ï¸ N-gram training feature temporarily disabled - KanaKanjiConverter integration required")
            print("âœ… Training process completed (feature disabled)")
        } catch {
            print("âŒ Failed to train N-gram model: \\(error)")
        }

        // WIP ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        do {
            try fileManager.removeItem(at: wipFileURL)
        } catch {
            print("âŒ Failed to remove WIP file: \(error)")
        }

        // lm ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ”ãƒ¼å‡¦ç†ã¯ trainNGramFromTextEntries ã§è¡Œã†ãŸã‚ã€ã“ã“ã‹ã‚‰ã¯å‰Šé™¤
    }
    
    
    /// ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰N-gramãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    /// - Parameters:
    ///   - ngramSize: N-gramã®ã‚µã‚¤ã‚º
    ///   - baseFilename: ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å
    ///   - maxEntryCount: æœ€å¤§ã‚¨ãƒ³ãƒˆãƒªæ•°
    func trainNGramFromTextEntries(ngramSize: Int = 5, baseFilePattern: String = "original", maxEntryCount: Int = 100_000) async {
        let fileManager = self.fileManager
        
        let savedTexts = await loadFromFileAsync()
        
        let importFileURL = getTextEntryDirectory().appendingPathComponent("import.jsonl") // Use TextEntry directory
        var importEntries: [TextEntry] = []
        if fileManager.fileExists(atPath: importFileURL.path) {
            if let fileContents = try? String(contentsOf: importFileURL, encoding: .utf8) {
                let lines = fileContents.split(separator: "\n")
                for line in lines {
                    guard !line.isEmpty else { continue }
                    if let jsonData = line.data(using: .utf8),
                       let entry = try? JSONDecoder().decode(TextEntry.self, from: jsonData) {
                        importEntries.append(entry)
                    }
                }
            }
        }
        
        let combinedEntries = savedTexts + importEntries
        let trainingEntries = combinedEntries.suffix(maxEntryCount)
        let lines = trainingEntries.map { $0.text }
        
        let outputDirURL = getLMDirectory() // Use the LM directory function
        let outputDir = outputDirURL.path
        
        do {
            try fileManager.createDirectory(atPath: outputDir, withIntermediateDirectories: true, attributes: nil)
        } catch {
            print("âŒ Failed to create directory: \(error)")
            return
        }
        
        if baseFilePattern == "original" {
            let lmFiles = [
                "lm_c_abc.marisa",
                "lm_u_abx.marisa",
                "lm_u_xbc.marisa",
                "lm_r_xbx.marisa",
                "lm_c_bc.marisa",
            ]
            for lmFile in lmFiles {
                let lmFilePath = URL(fileURLWithPath: outputDir).appendingPathComponent(lmFile).path
                if fileManager.fileExists(atPath: lmFilePath) {
                    do {
                        try fileManager.removeItem(atPath: lmFilePath)
                    } catch {
                        print("âŒ Failed to remove lm file \(lmFile): \(error)")
                    }
                }
            }
        }
        
        // N-gramå­¦ç¿’æ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
        print("ğŸ”„ Starting N-gram training from text entries...")
        print("âš ï¸ N-gram training feature temporarily disabled - KanaKanjiConverter integration required")
        print("âœ… Training process completed (feature disabled)")

        // ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå¾Œã€è¿½åŠ å­¦ç¿’ç”¨ã®lmãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦æº–å‚™ (baseFilePattern == "original" ã®å ´åˆã®ã¿)
        if baseFilePattern == "original" {
            let originalFiles = [
                "original_c_abc.marisa",
                "original_u_abx.marisa",
                "original_u_xbc.marisa",
                "original_r_xbx.marisa",
                "original_c_bc.marisa",
            ]
            let lmFiles = [
                "lm_c_abc.marisa",
                "lm_u_abx.marisa",
                "lm_u_xbc.marisa",
                "lm_r_xbx.marisa",
                "lm_c_bc.marisa",
            ]

            print("Copying original models to lm models after training...")
            for (origFile, lmFile) in zip(originalFiles, lmFiles) {
                let origPath = URL(fileURLWithPath: outputDir).appendingPathComponent(origFile).path
                let lmPath = URL(fileURLWithPath: outputDir).appendingPathComponent(lmFile).path
                
                // æ—¢å­˜ã® lm ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å‰Šé™¤
                if fileManager.fileExists(atPath: lmPath) {
                    do {
                        try fileManager.removeItem(atPath: lmPath)
                        print("  Removed existing lm file: \(lmFile)")
                    } catch {
                        print("âŒ Failed to remove existing lm file \(lmFile): \(error)")
                    }
                }
                
                // original ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚Œã°ã‚³ãƒ”ãƒ¼
                if fileManager.fileExists(atPath: origPath) {
                    do {
                        try fileManager.copyItem(at: URL(fileURLWithPath: origPath), to: URL(fileURLWithPath: lmPath))
                        print("  Copied \(origFile) to \(lmFile)")
                    } catch {
                        print("âŒ Error duplicating \(origFile) to \(lmFile): \(error)")
                    }
                } else {
                    print("âš ï¸ Original file \(origFile) not found, cannot copy to \(lmFile).")
                }
            }
        }

        await MainActor.run {
            self.lastNGramTrainingDate = Date()
        }
    }
}

// MARK: - æ‰‹å‹•ã§ã®è¿½åŠ å­¦ç¿’
extension TextModel {
    /// æ‰‹å‹•ã§N-gramãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ å­¦ç¿’ (lm) ã‚’å®Ÿè¡Œã™ã‚‹
    func trainIncrementalNGramManually() async {
        print("Starting manual incremental N-gram training (lm)...")
        
        // --- äº‹å‰ãƒã‚§ãƒƒã‚¯: å¿…è¦ãª lm ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª ---
        let fileManager = self.fileManager
        let lmDirURL = getLMDirectory()
        let expectedLmFiles = [
            "lm_c_abc.marisa",
            "lm_u_abx.marisa",
            "lm_u_xbc.marisa",
            "lm_r_xbx.marisa",
            "lm_c_bc.marisa"
        ]
        var allLmFilesExist = true
        print("  Checking for existing LM files in: \(lmDirURL.path)")
        for lmFile in expectedLmFiles {
            let lmPath = lmDirURL.appendingPathComponent(lmFile).path
            if fileManager.fileExists(atPath: lmPath) {
                print("    Found: \(lmFile)")
            } else {
                print("    âŒ MISSING: \(lmFile)")
                allLmFilesExist = false
            }
        }
        
        guard allLmFilesExist else {
            print("  Required LM files are missing. Aborting incremental training.")
            print("  Please run 'N-gramå†æ§‹ç¯‰ (å…¨ãƒ‡ãƒ¼ã‚¿)' first to create the initial LM models.")
            // ã“ã“ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ãªã©ã®å‡¦ç†ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
            return
        }
        print("  All required LM files found.")
        // --- äº‹å‰ãƒã‚§ãƒƒã‚¯å®Œäº† ---
        
        // savedTexts.jsonl ã‹ã‚‰èª­ã¿è¾¼ã¿
        let savedTexts = await loadFromFileAsync()
        print("  Loaded \(savedTexts.count) entries from savedTexts.jsonl")
        
        // import.jsonl ã‹ã‚‰èª­ã¿è¾¼ã¿
        let importTexts = await loadFromImportFileAsync()
        print("  Loaded \(importTexts.count) entries from import.jsonl")
        
        // ä¸¡æ–¹ã‚’çµåˆ
        let combinedEntries = savedTexts + importTexts
        print("  Total entries for training: \(combinedEntries.count)")
        
        guard !combinedEntries.isEmpty else {
            print("No entries found to train. Aborting incremental training.")
            // å¿…è¦ã§ã‚ã‚Œã°ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€šçŸ¥ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
            return
        }
        
        // trainNGramOnNewEntries ã‚’ lm ãƒ¢ãƒ¼ãƒ‰ã§å‘¼ã³å‡ºã™
        // trainNGramOnNewEntries ã¯å†…éƒ¨ã§ trainNGram ã‚’å‘¼ã³å‡ºã—ã€
        // resumeFilePattern="lm" ã«ã‚ˆã‚Šæ—¢å­˜ã® lm ãƒ¢ãƒ‡ãƒ«ã«è¿½è¨˜å­¦ç¿’ã™ã‚‹
        await trainNGramOnNewEntries(newEntries: combinedEntries, ngramSize: self.ngramSize, baseFilePattern: "lm")
        
        // æœ€çµ‚è¨“ç·´æ—¥æ™‚ã‚’æ›´æ–°
        await MainActor.run {
            self.lastNGramTrainingDate = Date()
            print("Manual incremental N-gram training (lm) finished at \(self.lastNGramTrainingDate!)")
        }
    }
    
    /// ç ´æã—ãŸMARISAãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    func cleanupCorruptedMARISAFiles() {
        let marisaFiles = [
            "lm_c_abc.marisa",
            "lm_u_abx.marisa", 
            "lm_u_xbc.marisa",
            "lm_r_xbx.marisa",
            "lm_c_bc.marisa",
            "original_c_abc.marisa",
            "original_u_abx.marisa",
            "original_u_xbc.marisa", 
            "original_r_xbx.marisa",
            "original_c_bc.marisa"
        ]
        
        let lmDirectory = getLMDirectory()
        
        for file in marisaFiles {
            let filePath = lmDirectory.appendingPathComponent(file).path
            
            if fileManager.fileExists(atPath: filePath) {
                do {
                    let attributes = try fileManager.attributesOfItem(atPath: filePath)
                    let fileSize = attributes[.size] as? Int64 ?? 0
                    
                    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ0ãƒã‚¤ãƒˆã¾ãŸã¯ç•°å¸¸ã«å°ã•ã„å ´åˆã¯å‰Šé™¤
                    if fileSize == 0 {
                        try fileManager.removeItem(atPath: filePath)
                        print("ğŸ—‘ï¸ Removed corrupted MARISA file (0 bytes): \(file)")
                    }
                } catch {
                    print("âš ï¸ Cannot check MARISA file \(file): \(error)")
                    // ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤ã‚’è©¦è¡Œ
                    try? fileManager.removeItem(atPath: filePath)
                    print("ğŸ—‘ï¸ Removed inaccessible MARISA file: \(file)")
                }
            }
        }
    }
    
    /// MARISAãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ã‚’æ¤œè¨¼
    private func validateMARISAFile(at path: String) -> Bool {
        guard fileManager.fileExists(atPath: path) else { 
            return false 
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
        do {
            let attributes = try fileManager.attributesOfItem(atPath: path)
            let fileSize = attributes[.size] as? Int64 ?? 0
            return fileSize > 0
        } catch {
            print("âŒ Cannot read MARISA file attributes: \(error)")
            return false
        }
    }
} 