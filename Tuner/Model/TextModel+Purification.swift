import Foundation

// MARK: - Purification
extension TextModel {
    /// ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ã‚¨ãƒ³ãƒˆãƒªã‚’é™¤å»ã—ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
    /// - Parameters:
    ///   - avoidApps: é™¤å¤–ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åã®ãƒªã‚¹ãƒˆ
    ///   - minTextLength: æœ€å°ãƒ†ã‚­ã‚¹ãƒˆé•·
    ///   - completion: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†æ™‚ã«å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    func purifyFile(avoidApps: [String], minTextLength: Int, completion: @escaping () -> Void) {
        let fileURL = getFileURL()
        let tempFileURL = getTextEntryDirectory().appendingPathComponent("tempSavedTexts.jsonl")

        loadFromFile { loadedTexts in
            if loadedTexts.isEmpty {
                print("No texts loaded from file - skipping purify to avoid empty file")
                completion()
                return
            }

            // MinHashã‚’ä½¿ç”¨ã—ãŸé‡è¤‡æ¤œå‡ºã¨å‰Šé™¤
            let minHash = MinHashOptimized(numHashFunctions: 20)
            let avoidAppsSet = Set(avoidApps)
            
            // ãƒã‚±ãƒƒãƒˆãƒ™ãƒ¼ã‚¹ã®é‡è¤‡æ¤œå‡º
            var buckets: [Int: [TextEntry]] = [:]
            var uniqueEntries: [TextEntry] = []
            var duplicateCount = 0
            var potentialDuplicates: [(TextEntry, TextEntry, Double)] = [] // ãƒ‡ãƒãƒƒã‚°ç”¨
            
            // ãƒã‚±ãƒƒãƒˆã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
            func getBucket(signature: [Int]) -> Int {
                var hasher = Hasher()
                signature[0..<3].forEach { hasher.combine($0) }
                return hasher.finalize()
            }
            
            for entry in loadedTexts {
                // é™¤å¤–ã‚¢ãƒ—ãƒªã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if avoidAppsSet.contains(entry.appName) || entry.text.count < minTextLength {
                    continue
                }
                
                let signature = minHash.computeMinHashSignature(for: entry.text)
                let bucket = getBucket(signature: signature)
                
                var isDuplicate = false
                
                // åŒã˜ãƒã‚±ãƒƒãƒˆå†…ã®ã‚¨ãƒ³ãƒˆãƒªã¨ã®ã¿æ¯”è¼ƒ
                if let existingEntries = buckets[bucket] {
                    for existingEntry in existingEntries {
                        // å®Œå…¨ä¸€è‡´ã®å ´åˆã¯å¿…ãšé‡è¤‡ã¨åˆ¤å®š
                        if entry.text == existingEntry.text {
                            isDuplicate = true
                            duplicateCount += 1
                            print("ğŸ” å®Œå…¨ä¸€è‡´ã«ã‚ˆã‚‹é‡è¤‡ã‚’æ¤œå‡º: [\(entry.appName)] \(entry.text)")
                            break
                        }
                        
                        // ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã®å·®ãŒå¤§ãã„å ´åˆã¯é‡è¤‡ã¨åˆ¤å®šã—ãªã„
                        let lengthDiff = abs(entry.text.count - existingEntry.text.count)
                        let maxLength = max(entry.text.count, existingEntry.text.count)
                        if Double(lengthDiff) / Double(maxLength) > 0.1 { // 0.2ã‹ã‚‰0.1ã«å¤‰æ›´
                            continue
                        }
                        
                        // é¡ä¼¼åº¦ãŒ0.98ä»¥ä¸Šã®å ´åˆã®ã¿é‡è¤‡ã¨ã¿ãªã™ï¼ˆ0.95ã‹ã‚‰0.98ã«å¤‰æ›´ï¼‰
                        let existingSignature = minHash.computeMinHashSignature(for: existingEntry.text)
                        let similarity = minHash.computeJaccardSimilarity(signature1: signature, signature2: existingSignature)
                        
                        // ãƒ‡ãƒãƒƒã‚°ç”¨ã«é¡ä¼¼åº¦ãŒé«˜ã„ãƒšã‚¢ã‚’è¨˜éŒ²
                        if similarity >= 0.95 { // 0.98æœªæº€ã§ã‚‚0.95ä»¥ä¸Šã®å ´åˆã¯è¨˜éŒ²
                            potentialDuplicates.append((entry, existingEntry, similarity))
                        }
                        
                        if similarity >= 0.98 { // 0.95ã‹ã‚‰0.98ã«å¤‰æ›´
                            isDuplicate = true
                            duplicateCount += 1
                            print("ğŸ” é¡ä¼¼åº¦ã«ã‚ˆã‚‹é‡è¤‡ã‚’æ¤œå‡º: [\(entry.appName)] \(entry.text)")
                            print("  é¡ä¼¼åº¦: \(similarity), æ—¢å­˜ãƒ†ã‚­ã‚¹ãƒˆ: \(existingEntry.text)")
                            break
                        }
                    }
                }
                
                if !isDuplicate {
                    uniqueEntries.append(entry)
                    buckets[bucket, default: []].append(entry)
                }
            }
            
            // ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›
            if !potentialDuplicates.isEmpty {
                print("\nğŸ” é«˜é¡ä¼¼åº¦ãƒšã‚¢ã®ä¸€è¦§:")
                for (entry1, entry2, similarity) in potentialDuplicates {
                    print("  é¡ä¼¼åº¦: \(similarity)")
                    print("  ãƒ†ã‚­ã‚¹ãƒˆ1: [\(entry1.appName)] \(entry1.text)")
                    print("  ãƒ†ã‚­ã‚¹ãƒˆ2: [\(entry2.appName)] \(entry2.text)")
                    print("  ---")
                }
            }
            
            if duplicateCount == 0 {
                print("No duplicates found - skipping file update")
                completion()
                return
            }

            print("Found \(duplicateCount) duplicates out of \(loadedTexts.count) entries")

            self.fileAccessQueue.async {
                // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
                let backupFileURL = self.getTextEntryDirectory().appendingPathComponent("backup_savedTexts_\(Int(Date().timeIntervalSince1970)).jsonl")
                do {
                    try FileManager.default.copyItem(at: fileURL, to: backupFileURL)
                    print("Backup file created at: \(backupFileURL.path)")
                } catch {
                    print("Failed to create backup file: \(error.localizedDescription)")
                }

                // æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                do {
                    var tempFileHandle: FileHandle?

                    if !FileManager.default.fileExists(atPath: tempFileURL.path) {
                        FileManager.default.createFile(atPath: tempFileURL.path, contents: nil, attributes: nil)
                    }

                    tempFileHandle = try FileHandle(forWritingTo: tempFileURL)
                    tempFileHandle?.seekToEndOfFile()

                    var writeSuccess = false
                    var entriesWritten = 0

                    for textEntry in uniqueEntries {
                        let jsonData = try JSONEncoder().encode(textEntry)
                        if let jsonString = String(data: jsonData, encoding: .utf8) {
                            let jsonLine = jsonString + "\n"
                            if let data = jsonLine.data(using: .utf8) {
                                tempFileHandle?.write(data)
                                entriesWritten += 1
                                writeSuccess = true
                            }
                        }
                    }

                    tempFileHandle?.closeFile()

                    if writeSuccess && entriesWritten > 0 {
                        try FileManager.default.removeItem(at: fileURL)
                        try FileManager.default.moveItem(at: tempFileURL, to: fileURL)
                        try? FileManager.default.removeItem(at: backupFileURL)
                        print("File purify completed. Removed \(duplicateCount) duplicated entries. Wrote \(entriesWritten) entries. Backup file deleted.")
                        
                        DispatchQueue.main.async {
                            self.lastPurifyDate = Date()
                        }
                    } else {
                        print("âš ï¸ Write was not successful or no entries were written - keeping original file")
                        try? FileManager.default.removeItem(at: tempFileURL)
                    }
                } catch {
                    print("Failed to clean and update file: \(error.localizedDescription)")
                    try? FileManager.default.removeItem(at: tempFileURL)
                }

                DispatchQueue.main.async {
                    completion()
                }
            }
        }
    }

    // å¤ã„purifyTextEntriesé–¢æ•° (MinHashã‚’ä½¿ã‚ãªã„æ–¹å¼) - å¿µã®ãŸã‚ã«æ®‹ã—ã¦ãŠã
    func purifyTextEntriesSimple(_ entries: [TextEntry], avoidApps: [String], minTextLength: Int) -> ([TextEntry], Int) {
        print("purity start... \(entries.count)")
        var textEntries: [TextEntry] = []
        var uniqueEntries: Set<String> = []
        var duplicatedCount = 0
        
        for entry in entries {
            // è¨˜å·ã®ã¿ã®ã‚¨ãƒ³ãƒˆãƒªã¯å‰Šé™¤
            if entry.text.utf16.isSymbolOrNumber {
                continue
            }
            
            // é™¤å¤–ã‚¢ãƒ—ãƒªã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if avoidApps.contains(entry.appName) || minTextLength > entry.text.utf8.count {
                continue
            }
            
            // é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ãŸã‚ã®ã‚­ãƒ¼ç”Ÿæˆ
            let uniqueKey = "\(entry.appName)-\(entry.text)"
            if uniqueEntries.contains(uniqueKey) {
                duplicatedCount += 1
                continue
            }
            
            uniqueEntries.insert(uniqueKey)
            textEntries.append(entry)
        }
        
        // å‰å¾Œã®è¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå‰æ–¹ä¸€è‡´ã—ã¦ã„ã‚‹å ´åˆã€çŸ­ã„æ–¹ã‚’å‰Šé™¤
        var index = 0
        while index < textEntries.count - 1 {
            // ã‚¢ãƒ—ãƒªåãŒç•°ãªã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if textEntries[index].appName != textEntries[index + 1].appName {
                index += 1
                continue
            }
            
            let currentText = textEntries[index].text.utf16
            let nextText = textEntries[index + 1].text.utf16
            
            if currentText.starts(with: nextText) || nextText.starts(with: currentText) {
                textEntries.remove(at: index + 1)
            } else {
                index += 1
            }
        }
        
        print("purity end... \(textEntries.count)")
        return (textEntries, duplicatedCount)
    }
} 