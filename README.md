# Tuner

Tunerは、ユーザーが表示したアプリのテキストを継続的に記録・分析するためのmacOSアプリケーションです。

## 特徴

- **継続的なテキスト記録**: macOSのアクセシビリティ機能を利用し、アクティブなアプリケーションのテキスト要素を自動的に取得・保存します。
- **効率的なデータ管理**: 収集したデータはJSONL形式で保存され、追記型のファイル操作により効率的に管理されます。
- **データ品質の維持**: 最小テキスト長、最大テキスト長（デフォルト: 1000文字）、記号/数字のみのテキスト除外など、基本的なフィルタリングを行います。
- **高度なデータ浄化**: セクション分割による大量データ対応と、インテリジェントな戦略選択により、CPU使用率を抑えながら効率的に重複・類似テキストを除去します。前方一致文字列（70%以上の一致率）の検出により、より完全な文字列のみを保持します。
- **N-gramモデル学習**: 収集したテキストを利用してN-gram言語モデルを構築・追加学習します。
- **統計情報の可視化**: アプリごとのテキスト量、言語割合などの統計情報を表示します。
- **外部データ連携**: テキストファイルのインポート機能や、指定したアプリグループ (`group.dev.ensan.inputmethod.azooKeyMac`) を介したデータ共有が可能です。
- **アプリケーション除外機能**: 現在実行中のアプリケーションから、テキスト取得を除外したいアプリを簡単に選択できます。

### 保存プロセス

1.  **テキスト取得**: アクセシビリティAPIまたはポーリングにより、テキストを取得します。
2.  **基本フィルタリング**: 空文字列、最小長未満、最大長（デフォルト: 1000文字）超過、記号/数字のみのテキストを除外します。
3.  **メモリ内バッファリング**: 新しく取得したテキストエントリは、一時的にメモリ内に保持されます。
4.  **ファイル追記**: 以下のいずれかの条件を満たした場合、メモリ上のテキストエントリが `savedTexts.jsonl` ファイルにJSONL形式で追記されます。
    *   メモリ内のエントリ数が一定数（デフォルト: 10件）に達した場合。
    *   最後にファイルへ保存してから一定時間（デフォルト: 5秒）が経過した場合。

### アプリケーション除外設定

- **実行中アプリの視覚的表示**: 現在実行中のアプリケーションをアイコン付きで表示し、監視中/除外中の状態がひと目でわかるように色分け表示します。
- **高速アプリ検索**: テキスト検索機能により、多数のアプリケーションから素早く目的のアプリを見つけられます。
- **除外アプリの一覧表示**: 現在除外中のアプリケーションを上部に一覧表示し、アイコンと名前で直感的に管理できます。
- **バックグラウンド処理**: アプリアイコンの取得を非同期で行い、UIのフリーズを防止します。
- **一括操作**: すべての除外設定をリセットする機能を備えています。
- **ステータス表示**: 監視中/除外中のアプリ数の概要をリアルタイムで表示します。
- **設定の永続化**: 除外設定は自動的に保存され、アプリケーションを再起動しても維持されます。
- **デフォルト除外**: FinderやTunerなど、特定のアプリケーションはデフォルトで除外されます。

### ノイズ除去 (データ浄化)

`savedTexts.jsonl` ファイルから重複・類似テキストを除去し、データ品質とストレージ効率を維持します。以下のタイミングで自動的に実行されます。

- **定期的実行**: 一定時間間隔（デフォルト: 1時間）ごとにバックグラウンドで実行されます (`AppDelegate` のタイマー制御)。
- **高頻度実行**: 新しいテキストエントリがメモリからファイルに追記される際、追記されたエントリ数が一定数（デフォルト: 100件）に達するごとに実行されます (`TextModel` 内のカウンター制御)。
- **アプリケーション終了時**: アプリケーションが終了する直前に、最終的な浄化処理が実行されます (`AppDelegate`)。

**処理内容**:
1.  `savedTexts.jsonl` ファイル全体を読み込みます。
2.  **前方一致重複除去**: 70%以上の前方一致を持つ文字列を効率的に検出し、より完全な長い文字列のみを保持します（例: 「おはy」「おはよ」「おはよう」→「おはよう」のみ残る）。
3.  MinHashアルゴリズムを用いて、類似度が高いテキストエントリ（類似度閾値デフォルト: 0.8）を検出します。
    *   **MinHashによる類似度検出の詳細**:
        *   **目的**: テキストエントリ数が膨大になっても、全てのペアを比較することなく、効率的に類似・重複する可能性のあるエントリを見つけ出します。
        *   **N-gram生成**: 各テキストを短い固定長の文字シーケンス（デフォルトでは3文字の**キャラクターN-gram**）に分割します。例えば、「こんにちは世界」は「こんに」「んにち」「にちは」「ちは世」「は世界」となります。
        *   **複数ハッシュ関数の適用**: 複数の（デフォルト: 20個）異なるハッシュ関数を用意します。これらのハッシュ関数は、それぞれ異なるシード値で初期化されており、同じ入力に対しても異なるハッシュ値を生成します。
        *   **MinHashシグネチャ計算**: 各テキストエントリについて、そのテキストから生成された全てのN-gramに対して、用意した全てのハッシュ関数を適用します。そして、**各ハッシュ関数ごとに**、そのテキスト内で計算されたハッシュ値の中での**最小値**を記録します。これにより、テキストごとにハッシュ関数の数と同じ長さの数値ベクトル（**MinHashシグネチャ**）が生成されます。このシグネチャは、元のテキストをコンパクトに表現した「指紋」のようなものです。
        *   **類似度計算 (Jaccard係数推定)**: 比較したい2つのテキストエントリのMinHashシグネチャを取り出します。2つのシグネチャの同じ位置（同じハッシュ関数に対応する位置）の値が一致している数を数えます。この一致数をシグネチャの全長（＝ハッシュ関数の数）で割ることで、元のテキスト間の類似度（Jaccard係数）を高速に**推定**します。理論的に、この推定値は元のテキストに含まれるN-gramの集合がどれだけ似ているかを示します。
        *   **閾値判定**: 上記で計算された類似度の推定値が、事前に設定された閾値（デフォルト: 0.8）以上であれば、これらのテキストエントリは「類似している」または「重複している」と判定されます。
        *   **最適化 (LRUキャッシュ)**: 一度計算したテキストとそのMinHashシグネチャのペアは、LRU（Least Recently Used）キャッシュに一時的に保存されます。これにより、同じテキストが再度出現した場合にシグネチャ計算をスキップでき、処理速度が向上します。
    *   **前方一致重複除去の詳細**:
        *   **目的**: 入力中の不完全な文字列（例：「おはy」「おはよ」）を検出し、より完全な文字列（例：「おはよう」）のみを保持することで、データ品質を向上させます。
        *   **検出方法**: 文字列を長さでソートし、各文字列が他の文字列の前方一致（prefix）であるかを効率的にチェックします（O(n²)の時間計算量）。
        *   **閾値判定**: 短い文字列の長さ ÷ 長い文字列の長さ が70%以上の場合、短い文字列を重複として削除します。
        *   **アプリ別処理**: 同一アプリケーション内でのみ前方一致チェックを行い、異なるアプリケーション間では処理しません。
        *   **実用例**: タイピング中の「こんに」「こんにち」「こんにちは」から「こんにちは」のみを保持し、不完全な入力履歴を自動的に除去します。
4.  重複・類似エントリを除去した内容で一時ファイルを生成します。
5.  一時ファイルの内容が有効（空でない）であれば、元の `savedTexts.jsonl` ファイルを置き換えます。

### テキスト学習

収集したテキストデータを利用してN-gram言語モデルを学習します。学習プロセスは、追加学習用の `lm` モデルと、ベースとなる `original` モデルの2種類があります。

- **増分学習 (Incremental Training) - `lm` モデル:**
    - **タイミング**: `savedTexts.jsonl` への **追記処理時** に自動的にトリガーされます。具体的には、ファイルに追記された新しいエントリ数が一定数（デフォルト: 500件）に達するごと。
    - **対象データ**: **直近でファイルに追記された** テキストエントリのみ。
    - **目的**: `original` モデルをベースとして、最新のテキスト傾向を反映させるための差分学習を行います。
    - **ファイル**: `lm_*.marisa` ファイル群が更新されます。初回実行時や `original` モデルの再構築後は、`original_*.marisa` ファイルがコピーされて `lm` モデルのベースとなります。

- **全体学習 (Full Training) - `original` モデル:**
    - **タイミング**: **自動実行**（設定で有効化時、デフォルト: 毎日3:00）または手動実行。データ浄化後など特定の条件下でも実行されます。
    - **対象データ**: `savedTexts.jsonl` と `import.jsonl` (インポート機能で生成されるファイル) の **全データ**（最大100,000エントリ）。
    - **目的**: 収集された全データ（または大部分）を用いて、ベースとなる言語モデル (`original_*.marisa`) を **再構築** します。
    - **影響**: この学習が実行されると、既存の `lm_*.marisa` ファイルは削除されます。

### テキストポーリング

- 設定可能なポーリング間隔でテキスト取得を行います。
- 特定アプリを除外するフィルタリングが可能です。

### 互換性

- `group.dev.ensan.inputmethod.azooKeyMac`アプリグループコンテナ内にデータを保存・共有します。
